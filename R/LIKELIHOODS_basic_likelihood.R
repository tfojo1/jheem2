#' @title Create JHEEM Basic Likelihood Instructions
#'
#' @param outcome.for.data A single character vector specifying the outcome that data managers will use to find data.
#' @param outcome.for.sim A single character vector specifying the simulation outcome to use.
#' @param dimensions A character vector of dimensions, excluding year, from which stratifications will be generated.
#' @param denominator.dimensions (Optional) Analogous to 'dimensions' but for the simulation denominator outcome when applicable. Must be a subset of 'dimensions'.
#' @param levels.of.stratification An integer vector specifying how the dimensions should be combined to form strata. '0' indicates totals (not stratified) while '1' indicates strata that are each stratified by one dimension at a time, '2' indicates strat that are each stratified by a combination of two dimensions at a time, etc. May not exceed the number of dimensions. Defaults to NULL, which is equivalent to '0'.
#' @param from.year -Inf or a single integer value specifying the earliest year for which data should be pulled.
#' @param to.year Inf or a single integer value specifying the latest year for which data should be pulled.
#' @param omit.years (Optional) An integer vector of years to ignore.
#' @param sources.to.use A character vector of sources from which to pull data.
#' @param correlation.different.years A single numeric value specifying the correlation between observations of different years.
#' @param correlation.different.strata A single numeric value specifying the correlation between observations from different strata.
#' @param correlation.different.sources A single numeric value specifying the correlation between observations from different sources.
#' @param correlation.same.source.different.details A single numeric value specifying the correlation between observations of the same source but which have different 'details'.
#' @param observation.correlation.form Which correlation form to use in building the measurement error covariance matrix. May be 'compound.symmetry' or 'autoregressive.1'.
#' @param error.variance.term If applicable for the 'error.variance.type' used, a single numeric value. If the 'error.variance.type' is 'function.sd', then this term should be a function that takes arguments 'data' and 'details' and returns a numeric array of the same dimensions as ‘data’, with no NA values, that represents the sd for each measurement in data.
#' @param error.variance.type A single character value specifying how the error variance is described. May refer to a single quantity with "sd" (standard deviation), "variance", "cv" (covariance); or may request the error variance be sourced from data with "data.sd", "data.variance", and "data.ci" (confidence interval). The error variance may be specified with more nuance if set to 'function.sd' (see description in 'error.variance.term' definition).
#' @param measurement.error.coefficient.of.variance A single numeric value specifying the coefficient of variance used to build the measurement error covariance matrix.
#' @param weights A list containing only numeric vectors and objects of class 'jheem.likelihood.weights', which are generated by \code{\link{create.likelihood.weights}}
#' @param equalize.weight.by.year A Boolean indicating whether every year should be weighted equally before the weights from 'weights' are applied.
#'
#' @export
create.basic.likelihood.instructions <- function(outcome.for.data,
                                                 outcome.for.sim,
                                                 dimensions = character(0),
                                                 denominator.dimensions = dimensions,
                                                 dimension.values = NULL, # EXPERIMENTAL
                                                 levels.of.stratification = NULL,
                                                 from.year = -Inf,
                                                 to.year = Inf,
                                                 omit.years = NULL,
                                                 sources.to.use = NULL,
                                                 correlation.different.years = 0.5,
                                                 correlation.different.strata = 0.1,
                                                 correlation.different.sources = 0.3,
                                                 correlation.same.source.different.details = 0.3,
                                                 observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
                                                 error.variance.term = NULL,
                                                 error.variance.type = NULL,
                                                 weights = list(),
                                                 equalize.weight.by.year = T) {
    JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS$new(
        outcome.for.data = outcome.for.data,
        outcome.for.sim = outcome.for.sim,
        outcome.value = NULL,
        dimensions = dimensions,
        denominator.dimensions = denominator.dimensions,
        dimension.values = dimension.values, # EXPERIMENTAL
        levels.of.stratification = levels.of.stratification,
        from.year = from.year,
        to.year = to.year,
        omit.years = omit.years,
        sources.to.use = sources.to.use,
        included.multiplier = NULL,
        included.multiplier.sd = NULL,
        included.multiplier.correlation = NULL,
        included.multiplier.correlation.structure = c("compound.symmetry", "autoregressive.1")[1],
        correlation.different.years = correlation.different.years,
        correlation.different.strata = correlation.different.strata,
        correlation.different.sources = correlation.different.sources,
        correlation.same.source.different.details = correlation.same.source.different.details,
        observation.correlation.form = observation.correlation.form,
        error.variance.term = error.variance.term,
        error.variance.type = error.variance.type,
        weights = weights,
        equalize.weight.by.year = equalize.weight.by.year,
        is.basic.ratio.likelihood = F
    )
}

#' @title Create JHEEM Basic Likelihood Instructions With Specified Outcome
#'
#' @inheritParams create.basic.likelihood.instructions
#' @param outcome.value A single, non-NA numeric value that is the value of the outcome at the totals level (i.e., not stratified).
#'
#' @export
create.basic.likelihood.instructions.with.specified.outcome <- function(outcome.for.sim, outcome.value,
                                                                        from.year,
                                                                        to.year,
                                                                        omit.years = NULL,
                                                                        correlation.different.years = 0.5,
                                                                        observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
                                                                        error.variance.term = NULL,
                                                                        error.variance.type = NULL,
                                                                        weights = list(),
                                                                        equalize.weight.by.year = T) {
    JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS$new(
        outcome.for.data = NULL,
        outcome.for.sim = outcome.for.sim,
        outcome.value = outcome.value,
        dimensions = character(0),
        denominator.dimensions = character(0),
        dimension.values = NULL, # EXPERIMENTAL
        levels.of.stratification = NULL,
        from.year = from.year,
        to.year = to.year,
        omit.years = omit.years,
        sources.to.use = NULL,
        included.multiplier = NULL,
        included.multiplier.sd = NULL,
        included.multiplier.correlation = NULL,
        included.multiplier.correlation.structure = c("compound.symmetry", "autoregressive.1")[1],
        correlation.different.years = correlation.different.years,
        correlation.different.strata = 0.1,
        correlation.different.sources = 0.3,
        correlation.same.source.different.details = 0.3,
        observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
        error.variance.term = error.variance.term,
        error.variance.type = error.variance.type,
        weights = weights,
        equalize.weight.by.year = equalize.weight.by.year,
        is.basic.ratio.likelihood = F
    )
}

#' @title Create JHEEM Basic Likelihood Instructions With Included Multiplier
#'
#' @inheritParams create.basic.likelihood.instructions
#' @param included.multiplier The value of the multiplier that has already been used in calculating the simulation value of the outcome (represents the mean of the distribution around the multiplier).
#' @param included.multiplier.sd The standard deviation of the uncertainty around the included multiplier.
#' @param included.multiplier.correlation The correlation between values of the multiplier across different strata and years.
#' @param included.multiplier.correlation.structure Which correlation form to use for values of the multiplier across various strata and years.
#'
#' @export
create.basic.likelihood.instructions.with.included.multiplier <- function(outcome.for.data,
                                                                          outcome.for.sim,
                                                                          dimensions = character(0),
                                                                          denominator.dimensions = dimensions,
                                                                          dimension.values = NULL, # EXPERIMENTAL
                                                                          levels.of.stratification = NULL,
                                                                          from.year = -Inf,
                                                                          to.year = Inf,
                                                                          omit.years = NULL,
                                                                          sources.to.use = NULL,
                                                                          included.multiplier,
                                                                          included.multiplier.sd,
                                                                          included.multiplier.correlation = NULL,
                                                                          included.multiplier.correlation.structure = c("compound.symmetry", "autoregressive.1")[1],
                                                                          correlation.different.years = 0.5,
                                                                          correlation.different.strata = 0.1,
                                                                          correlation.different.sources = 0.3,
                                                                          correlation.same.source.different.details = 0.3,
                                                                          observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
                                                                          error.variance.term = NULL,
                                                                          error.variance.type = NULL,
                                                                          weights = list(),
                                                                          equalize.weight.by.year = T) {
    JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS$new(
        outcome.for.data = outcome.for.data,
        outcome.for.sim = outcome.for.sim,
        outcome.value = NULL,
        dimensions = dimensions,
        denominator.dimensions = denominator.dimensions,
        dimension.values = dimension.values, # EXPERIMENTAL
        levels.of.stratification = levels.of.stratification,
        from.year = from.year,
        to.year = to.year,
        omit.years = omit.years,
        sources.to.use = sources.to.use,
        included.multiplier = included.multiplier,
        included.multiplier.sd = included.multiplier.sd,
        included.multiplier.correlation = included.multiplier.correlation,
        included.multiplier.correlation.structure = included.multiplier.correlation.structure,
        correlation.different.years = correlation.different.years,
        correlation.different.strata = correlation.different.strata,
        correlation.different.sources = correlation.different.sources,
        correlation.same.source.different.details = correlation.same.source.different.details,
        observation.correlation.form = observation.correlation.form,
        error.variance.term = error.variance.term,
        error.variance.type = error.variance.type,
        weights = weights,
        equalize.weight.by.year = equalize.weight.by.year,
        is.basic.ratio.likelihood = F
    )
}

#' @title Create JHEEM Basic Likelihood Instructions
#'
#' @inheritParams create.basic.likelihood.instructions
#' @param use.lognormal.approximation A single logical value.
#' @export
create.time.lagged.comparison.likelihood.instructions <- function(outcome.for.data,
                                                                  outcome.for.sim,
                                                                  dimensions = character(0),
                                                                  denominator.dimensions = dimensions,
                                                                  dimension.values = NULL, # EXPERIMENTAL
                                                                  levels.of.stratification = NULL,
                                                                  from.year = -Inf,
                                                                  to.year = Inf,
                                                                  omit.years = NULL,
                                                                  sources.to.use = NULL,
                                                                  correlation.different.years = 0.5,
                                                                  correlation.different.strata = 0.1,
                                                                  correlation.different.sources = 0.3,
                                                                  correlation.same.source.different.details = 0.3,
                                                                  observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
                                                                  error.variance.term = NULL,
                                                                  error.variance.type = NULL,
                                                                  ratio.cv = NULL,
                                                                  ratio.correlation = NULL,
                                                                  weights = list(),
                                                                  equalize.weight.by.year = T,
                                                                  use.lognormal.approximation = T) {
    JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS$new(
        outcome.for.data = outcome.for.data,
        outcome.for.sim = outcome.for.sim,
        outcome.value = NULL,
        dimensions = dimensions,
        denominator.dimensions = denominator.dimensions,
        dimension.values = dimension.values, # EXPERIMENTAL
        levels.of.stratification = levels.of.stratification,
        from.year = from.year,
        to.year = to.year,
        omit.years = omit.years,
        sources.to.use = sources.to.use,
        included.multiplier = NULL,
        included.multiplier.sd = NULL,
        included.multiplier.correlation = NULL,
        correlation.different.years = correlation.different.years,
        correlation.different.strata = correlation.different.strata,
        correlation.different.sources = correlation.different.sources,
        correlation.same.source.different.details = correlation.same.source.different.details,
        observation.correlation.form = observation.correlation.form,
        error.variance.term = error.variance.term,
        error.variance.type = error.variance.type,
        ratio.cv = ratio.cv,
        ratio.correlation = ratio.correlation,
        weights = weights,
        equalize.weight.by.year = equalize.weight.by.year,
        use.lognormal.approximation = use.lognormal.approximation,
        calculate.lagged.difference = T,
        is.basic.ratio.likelihood = F
    )
}

#' @title Create JHEEM Basic Likelihood Instructions
#'
#' @inheritParams create.basic.likelihood.instructions.with.included.multiplier
#' @param use.lognormal.approximation A single logical value.
#'
#' @export
create.time.lagged.comparison.likelihood.instructions.with.included.multiplier <- function(outcome.for.data,
                                                                                           outcome.for.sim,
                                                                                           dimensions = character(0),
                                                                                           denominator.dimensions = dimensions,
                                                                                           dimension.values = NULL, # EXPERIMENTAL
                                                                                           levels.of.stratification = NULL,
                                                                                           from.year = -Inf,
                                                                                           to.year = Inf,
                                                                                           omit.years = NULL,
                                                                                           sources.to.use = NULL,
                                                                                           included.multiplier,
                                                                                           included.multiplier.sd,
                                                                                           included.multiplier.correlation = NULL,
                                                                                           included.multiplier.correlation.structure = c("compound.symmetry", "autoregressive.1")[1],
                                                                                           correlation.different.years = 0.5,
                                                                                           correlation.different.strata = 0.1,
                                                                                           correlation.different.sources = 0.3,
                                                                                           correlation.same.source.different.details = 0.3,
                                                                                           observation.correlation.form = c("compound.symmetry", "autoregressive.1")[1],
                                                                                           error.variance.term = NULL,
                                                                                           error.variance.type = NULL,
                                                                                           weights = list(),
                                                                                           equalize.weight.by.year = T,
                                                                                           use.lognormal.approximation = T) {
    JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS$new(
        outcome.for.data = outcome.for.data,
        outcome.for.sim = outcome.for.sim,
        outcome.value = NULL,
        dimensions = dimensions,
        denominator.dimensions = denominator.dimensions,
        dimension.values = dimension.values, # EXPERIMENTAL
        levels.of.stratification = levels.of.stratification,
        from.year = from.year,
        to.year = to.year,
        omit.years = omit.years,
        sources.to.use = sources.to.use,
        included.multiplier = included.multiplier,
        included.multiplier.sd = included.multiplier.sd,
        included.multiplier.correlation = included.multiplier.correlation,
        included.multiplier.correlation.structure = included.multiplier.correlation.structure,
        correlation.different.years = correlation.different.years,
        correlation.different.strata = correlation.different.strata,
        correlation.different.sources = correlation.different.sources,
        correlation.same.source.different.details = correlation.same.source.different.details,
        observation.correlation.form = observation.correlation.form,
        error.variance.term = error.variance.term,
        error.variance.type = error.variance.type,
        weights = weights,
        equalize.weight.by.year = equalize.weight.by.year,
        use.lognormal.approximation = use.lognormal.approximation,
        calculate.lagged.difference = T,
        is.basic.ratio.likelihood = F
    )
}

JHEEM.BASIC.LIKELIHOOD.INSTRUCTIONS <- R6::R6Class(
    "jheem.basic.likelihood.instructions",
    inherit = JHEEM.LIKELIHOOD.INSTRUCTIONS,
    public = list(
        initialize = function(outcome.for.data,
                              outcome.for.sim,
                              outcome.value,
                              dimensions,
                              denominator.dimensions,
                              dimension.values, # EXPERIMENTAL
                              levels.of.stratification,
                              from.year,
                              to.year,
                              omit.years,
                              sources.to.use,
                              included.multiplier,
                              included.multiplier.sd,
                              included.multiplier.correlation,
                              included.multiplier.correlation.structure = c("compound.symmetry", "autoregressive.1")[1],
                              correlation.different.years,
                              correlation.different.strata,
                              correlation.different.sources,
                              correlation.same.source.different.details,
                              observation.correlation.form,
                              error.variance.term,
                              error.variance.type,
                              ratio.cv = NULL,
                              ratio.correlation = NULL,
                              weights,
                              equalize.weight.by.year,
                              use.lognormal.approximation = F,
                              calculate.lagged.difference = F,
                              is.basic.ratio.likelihood = F) {
            # browser()
            error.prefix <- paste0("Error creating basic likelihood instructions for outcome '", outcome.for.sim, "': ")
            
            # *outcome.for.sim* -- validated in the super$initialize
            
            # *outcome.for.data* is a single character vector, or NULL if "outcome.value" is not NULL
            if (is.null(outcome.value) && (!is.character(outcome.for.data) || length(outcome.for.data) > 1 || is.null(outcome.for.data) || is.na(outcome.for.data))) {
                stop(paste0(error.prefix, "'outcome.for.data' must be a character vector of length 1"))
            }
            
            # *outcome.value* must be NULL or a single numeric value
            if (!is.null(outcome.value) && (!is.numeric(outcome.value) || length(outcome.value) != 1 || is.na(outcome.value))) {
                stop(paste0(error.prefix, "'outcome.value' must be NULL or a single numeric value"))
            }
            
            # *outcome.value* must be NULL if *dimensions*, *denominator.dimensions*, *dimension.values*, or *levels.of.stratification* is not NULL/0
            if (!is.null(outcome.value) && (length(dimensions) != 0 || length(denominator.dimensions) != 0 || !is.null(dimension.values) || (!is.null(levels.of.stratification) && levels.of.stratification == 0))) {
                stop(paste0(error.prefix, "'outcome.value' cannot be used with arguments that imply stratification beyond totals-level"))
            }
            
            # otherwise, it must be a single, numeric value
            if (!is.null(outcome.value) && (!is.numeric(outcome.value) || length(outcome.value) != 1 || is.na(outcome.value))) {
                stop(paste0(error.prefix, "'outcome.value' must be a single, non-NA numeric value"))
            }
            
            # *dimensions* -- validated in the super$initialize
            
            # *denominator.dimensions* is NULL or a character vector with no NAs or duplicates
            # AND which is a subset of *dimensions*
            if (!is.null(denominator.dimensions) && (!is.character(denominator.dimensions) || any(is.na(denominator.dimensions)) || any(duplicated(dimensions))) || length(setdiff(denominator.dimensions, dimensions)) > 0) {
                stop(paste0(error.prefix, "'denominator dimensions' must be NULL or a character vector with no NAs or duplicates that is a subset of 'dimensions'"))
            }
            
            # *levels.of.stratification* -- validated in the super$initialize
            
            # *from.year* and *to.year* are single integer vectors. *to.year* must be larger than *from.year*.
            if (from.year != -Inf && (!is.numeric(from.year) || length(from.year) > 1 || is.null(from.year) || is.na(from.year))) {
                stop(paste0(error.prefix, "'from.year' must be -Inf or a numeric vector of length 1"))
            }
            if (to.year != Inf && (!is.numeric(to.year) || length(to.year) > 1 || is.null(to.year) || is.na(to.year))) {
                stop(paste0(error.prefix, "'to.year' must be Inf or a numeric vector of length 1"))
            }
            if (from.year > to.year) {
                stop(paste0(error.prefix, "'from.year' must be less than 'to.year'"))
            }
            
            # *omit.years* is NULL or a numeric vector containing no NAs or duplicates.
            if (!is.null(omit.years) && (!is.numeric(omit.years) || any(is.na(omit.years)) || any(duplicated(omit.years)))) {
                stop(paste0(error.prefix, "'omit.years' must be NULL or an numeric vector containing no NAs or duplicates"))
            }
            omit.years <- as.integer(omit.years)
            
            # *from.year* and *to.year* cannot be Inf/-Inf if *outcome.value* is being used
            if (!is.null(outcome.value) && (from.year == -Inf || to.year == Inf)) {
                stop(paste0(error.prefix, "'from.year' and 'to.year' must be define if 'outcome.value' is supplied"))
            }
            
            # *sources.to.use* is NULL or a character vector containing no NAs or duplicates
            if (!is.null(sources.to.use) && (!is.character(sources.to.use) || any(is.na(sources.to.use)) || any(duplicated(sources.to.use)))) {
                stop(paste0(error.prefix, "'sources.to.use' must be NULL or a character vector containing no NAs or duplicates"))
            }
            
            # *included.multiplier* is NULL, a single numeric value, or a named numeric vector with names corresponding to years or year ranges.
            if (!is.null(included.multiplier) &&
                (!is.numeric(included.multiplier) || length(included.multiplier) != 1 || is.na(included.multiplier) || included.multiplier <= 0) &&
                (!is.numeric(included.multiplier) || is.null(names(included.multiplier)) || any(is.na(included.multiplier)) || any(included.multiplier <= 0) || is.null(parse.year.names(names(included.multiplier))))) {
                stop(paste0(error.prefix, "'included.multiplier' must be one of: 1. NULL, 2. a single, non-NA, numeric value greater than 0, or 3. a named numeric vector with all values non-NA and greater than zero and names all corresponding to years or year ranges"))
            }
            
            # *included.multiplier.sd* is NULL, a single numeric value, or a named numeric vector with the same names as *included.multiplier*.
            if (!is.null(included.multiplier.sd) &&
                (!is.numeric(included.multiplier.sd) || length(included.multiplier.sd) != 1 || is.na(included.multiplier.sd) || included.multiplier.sd <= 0) &&
                (!is.numeric(included.multiplier.sd) || any(is.na(included.multiplier.sd)) || any(included.multiplier.sd <= 0) || !identical(names(included.multiplier.sd), names(included.multiplier)))) {
                stop(paste0(error.prefix, "'included.multiplier.sd' must be one of: 1. NULL, 2. a single, non-NA, numeric value greater than 0, or 3. a named numeric vector with all values non-NA and greater than zero and the same names as 'included.multiplier'"))
            }
            # and cannot be NULL if *included.multiplier* is not NULL
            if (!is.null(included.multiplier) && is.null(included.multiplier.sd)) {
                stop(paste0(error.prefix, "'included.multiplier.sd' cannot be NULL if 'included.multiplier' is not also NULL"))
            }
            
            # *included.multiplier.correlation* is NULL or a single numeric value between 0 and 1.
            if (!is.null(included.multiplier.correlation) &&
                (!is.numeric(included.multiplier.correlation) || length(included.multiplier.correlation) != 1 || included.multiplier.correlation <= 0 || included.multiplier.correlation >= 1)) {
                stop(paste0(error.prefix, "'included.multiplier.correlation' must be NULL or a single numeric value between 0 and 1"))
            }
            # and cannot be NULL if *included.multiplier* is not NULL
            if (!is.null(included.multiplier) && is.null(included.multiplier.correlation)) {
                stop(paste0(error.prefix, "''included.multiplier.correlation' cannot be NULL if 'included.multiplier' is not also NULL"))
            }
            
            # *included.multiplier.correlation.structure* is 'compound.symmetry' or 'autoregressive.1'
            if (!is.character(included.multiplier.correlation.structure) || length(included.multiplier.correlation.structure) != 1 || !(included.multiplier.correlation.structure) %in% c("compound.symmetry", "autoregressive.1")) {
                stop(paste0(error.prefix, "'included.multiplier.correlation.structure' must be either 'compound.symmetry' or 'autoregressive.1'"))
            }
            
            # *correlation.multipliers* are all single numeric vectors with values between 0 and 1 inclusive
            correlation.multipliers <- list(
                correlation.different.years = correlation.different.years,
                correlation.different.strata = correlation.different.strata,
                correlation.different.sources = correlation.different.sources,
                correlation.same.source.different.details = correlation.same.source.different.details
            )
            names(correlation.multipliers) <- c("correlation.different.years", "correlation.different.strata", "correlation.different.sources", "correlation.same.source.different.details")
            for (i in seq_along(correlation.multipliers)) {
                if (!is.numeric(correlation.multipliers[[i]]) || length(correlation.multipliers[[i]]) > 1 || is.na(correlation.multipliers[[i]]) || correlation.multipliers[[i]] > 1 || correlation.multipliers[[i]] < 0) {
                    stop(paste0(error.prefix, "'", names(correlation.multipliers)[[i]], "' must be a numeric value between 0 and 1 inclusive"))
                }
            }
            
            # *observation.correlation.form* is either 'compound.symmetry' or 'autoregressive.1'
            if (length(observation.correlation.form) > 1 || !(observation.correlation.form %in% c("compound.symmetry", "autoregressive.1"))) {
                stop(paste0(error.prefix, "'observation.correlation.form' must be either 'compound.symmetry' or 'autoregressive.1'"))
            }
            
            # # *measurement.error.coefficient.of.variance* must be a single numeric value between 0 and 1
            # if (!is.numeric(measurement.error.coefficient.of.variance) || length(measurement.error.coefficient.of.variance) > 1 || is.na(measurement.error.coefficient.of.variance) || measurement.error.coefficient.of.variance > 1 || measurement.error.coefficient.of.variance < 0)
            #     stop(paste0(error.prefix, "'measurement.error.coefficient.of.variance' must be a numeric value between 0 and 1 inclusive"))
            
            # *error.variance.type* must be one of 'sd', 'variance', 'cv', 'data.sd', 'data.ci', 'data.variance', or 'function.sd'
            if (!(error.variance.type %in% c("sd", "variance", "cv", "data.sd", "data.ci", "data.variance", "function.sd"))) {
                stop(paste0(error.prefix, "'error.variance.type' must be one of 'sd', 'variance', 'cv', 'data.sd', 'data.ci', 'data.variance', or 'function.sd'"))
            }
            
            if (error.variance.type %in% c("sd", "variance", "cv") && (!is.numeric(error.variance.term) || length(error.variance.term) != 1 || is.na(error.variance.term) || error.variance.term < 0)) {
                stop(paste0(error.prefix, "'error.variance.term' must be a single, nonnegative, numeric value if 'error.variance.type' is one of 'sd', 'variance', or 'cv'"))
            }
            if (error.variance.type %in% c("data.sd", "data.ci") && !is.null(error.variance.term)) {
                stop(paste0(error.prefix, "'error.variance.term' must be NULL if 'error.variance.term' is one of 'data.sd' or 'data.ci'"))
            }
            if (error.variance.type %in% c("function.sd") && (!is.function(error.variance.term) || !setequal(names(formals(error.variance.term)), c('data', 'details'))))
                stop(paste0(error.prefix, "if 'error.variance.type' is 'function.sd', then the 'error.variance.term' must be a function that takes arguments 'data' and 'details' and returns a numeric array of the same dimensions as ‘data’, with no NA values, that represents the sd for each measurement in data."))
            
            # *weights* -- validated in the super$initialize
            
            # *equalize.weight.by.year* is a boolean
            if (!is.logical(equalize.weight.by.year) || length(equalize.weight.by.year) > 1 || is.null(equalize.weight.by.year) || is.na(equalize.weight.by.year)) {
                stop(paste0(error.prefix, "'equalize.weight.by.year' must be a single logical value (T/F)"))
            }
            
            # EXPERIMENTAL DIMENSION VALUES SHOULD BE A NAMED LIST
            if (!is.null(dimension.values) && (!is.list(dimension.values) || (length(dimension.values) > 0 && is.null(names(dimension.values))) || "year" %in% names(dimension.values))) {
                stop(paste0(error.prefix, "experimental 'dimension.values' argument must be NULL or a named list without 'year'"))
            }
            
            # use.lognormal.approximation
            if (!is.logical(use.lognormal.approximation) || length(use.lognormal.approximation) != 1 || is.na(use.lognormal.approximation)) {
                stop(paste0(error.prefix, "'use.lognormal.approximation' must be a single logical value (T/F)"))
            }
            # calculate.lagged.difference
            if (!is.logical(calculate.lagged.difference) || length(calculate.lagged.difference) != 1 || is.na(calculate.lagged.difference)) {
                stop(paste0(error.prefix, "'calculate.lagged.difference' must be a single logical value (T/F)"))
            }
            # is.basic.ratio.likelihood
            if (!is.logical(is.basic.ratio.likelihood) || length(is.basic.ratio.likelihood) != 1 || is.na(is.basic.ratio.likelihood)) {
                stop(paste0(error.prefix, "'is.basic.ratio.likelihood' must be a single logical value (T/F)"))
            }
            
            # if *ratio.cv* is not NULL, then *ratio.correlation* can default to 0
            if (!is.null(ratio.cv) && is.null(ratio.correlation)) ratio.correlation = 0
            if (!is.null(ratio.cv) && (!is.numeric(ratio.cv) || length(ratio.cv)!=1 || is.na(ratio.cv)))
                stop(paste0(error.prefix, "'ratio.cv' must be NULL or a single, numeric value"))
            if (!is.null(ratio.correlation) && (!is.numeric(ratio.correlation) || length(ratio.correlation)!=1 || is.na(ratio.correlation) || ratio.correlation>1 || ratio.correlation< -1))
                stop(paste0(error.prefix, "'ratio.correlation' must be NULL or a single, numeric value between 1 and -1, inclusive"))
            
            super$initialize(
                outcome.for.sim = outcome.for.sim,
                dimensions = dimensions,
                levels.of.stratification = levels.of.stratification,
                weights = weights,
                likelihood.class.generator = if (is.basic.ratio.likelihood) JHEEM.BASIC.RATIO.LIKELIHOOD else JHEEM.BASIC.LIKELIHOOD,
                error.prefix = error.prefix
            )
            
            # if 'year' is in the dimension values for any *weights*, then *equalize.weight.by.year* must be FALSE
            if (equalize.weight.by.year && any(sapply(private$i.weights, function(weight) {
                "year" %in% names(weight$dimension.values)
            }))) {
                stop(paste0(error.prefix, "'equalize.weight.by.year' must be FALSE if any weights include 'year' in their dimension values"))
            }
            
            private$i.outcome.for.data <- outcome.for.data
            private$i.outcome.value <- outcome.value
            private$i.from.year <- from.year
            private$i.to.year <- to.year
            private$i.omit.years <- omit.years
            private$i.denominator.dimensions <- denominator.dimensions
            private$i.equalize.weight.by.year <- equalize.weight.by.year
            private$i.sources.to.use <- sources.to.use
            private$i.parameters <- list(
                included.multiplier = included.multiplier,
                included.multiplier.sd = included.multiplier.sd,
                included.multiplier.correlation = included.multiplier.correlation,
                included.multiplier.correlation.structure = included.multiplier.correlation.structure,
                correlation.different.years = correlation.different.years,
                correlation.different.strata = correlation.different.strata,
                correlation.different.sources = correlation.different.sources,
                correlation.same.source.different.details = correlation.same.source.different.details,
                observation.correlation.form = observation.correlation.form,
                error.variance.term = error.variance.term,
                error.variance.type = error.variance.type,
                ratio.cv = ratio.cv,
                ratio.correlation = ratio.correlation
            )
            private$i.dimension.values <- dimension.values # EXPERIMENTAL
            private$i.use.lognormal.approximation <- use.lognormal.approximation
            private$i.calculate.lagged.difference <- calculate.lagged.difference
            private$i.is.basic.ratio.likelihood <- is.basic.ratio.likelihood
        },
        equals = function(other) {
            if (!is(other, "jheem.likelihood.instructions")) {
                stop("'other' must be a 'jheem.likelihood.instructions' object")
            }
            if (!is.null(self$code) && !is.null(other$code)) {
                self$code == other$code
            } else {
                if (is(other, "jheem.basic.likelihood.instructions")) {
                    to.compare.identical <- c(
                        "description",
                        "outcome.for.data",
                        "outcome.for.sim",
                        "from.year",
                        "to.year",
                        "use.lognormal.approximation",
                        "calculate.lagged.difference"
                    )
                    to.compare.setequal <- c(
                        "sources.to.use",
                        "omit.years",
                        "denominator.dimensions"
                    )
                    
                    all(sapply(to.compare.identical, function(x) {
                        identical(self[[x]], other[[x]])
                    })) &&
                        all(sapply(to.compare.setequal, function(x) {
                            setequal(self[[x]], other[[x]])
                        })) &&
                        all(sapply(self$weights, function(x) {
                            any(sapply(other$weights, function(y) {
                                x$equals(y)
                            }))
                        })) &&
                        all(sapply(names(self$parameters), function(x) {
                            self$parameters[[x]] == other$parameters[[x]]
                        })) &&
                        private$stratification.lists.equal(self$stratifications, other$stratifications)
                } else {
                    F
                }
            }
        }
    ),
    active = list(
        outcome.for.data = function(value) {
            if (missing(value)) {
                private$i.outcome.for.data
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'outcome.for.data' - it is read-only")
            }
        },
        outcome.value = function(value) {
            if (missing(value)) {
                private$i.outcome.value
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'outcome.value' - it is read-only")
            }
        },
        from.year = function(value) {
            if (missing(value)) {
                private$i.from.year
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'from.year' - it is read-only")
            }
        },
        to.year = function(value) {
            if (missing(value)) {
                private$i.to.year
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'to.year' - it is read-only")
            }
        },
        omit.years = function(value) {
            if (missing(value)) {
                private$i.omit.years
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'omit.years' - they are read-only")
            }
        },
        denominator.dimensions = function(value) {
            if (missing(value)) {
                private$i.denominator.dimensions
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'denominator.dimensions' - they are read-only")
            }
        },
        equalize.weight.by.year = function(value) {
            if (missing(value)) {
                private$i.equalize.weight.by.year
            } else {
                stop("Cannot modify a jheem.likelihood.instruction's 'equalize.weight.by.year' - it is read-only")
            }
        },
        parameters = function(value) {
            if (missing(value)) {
                private$i.parameters
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's 'parameters' - they are read-only")
            }
        },
        sources.to.use = function(value) {
            if (missing(value)) {
                private$i.sources.to.use
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's 'sources.to.use' - they are read-only")
            }
        },
        dimension.values = function(value) # EXPERIMENTAL
        {
            if (missing(value)) {
                private$i.dimension.values
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's experimental 'dimension.values' - they are read-only")
            }
        },
        use.lognormal.approximation = function(value) {
            if (missing(value)) {
                private$i.use.lognormal.approximation
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's 'use.lognormal.approximation' - it is read-only")
            }
        },
        calculate.lagged.difference = function(value) {
            if (missing(value)) {
                private$i.calculate.lagged.difference
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's 'calculate.lagged.difference' - it is read-only")
            }
        },
        is.basic.ratio.likelihood = function(value) {
            if (missing(value)) {
                private$i.is.basic.ratio.likelihood
            } else {
                stop("Cannot modify a jheem.basic.likelihood.instruction's 'is.basic.ratio.likelihood' - it is read-only")
            }
        }
    ),
    private = list(
        i.outcome.for.data = NULL,
        i.outcome.value = NULL,
        i.from.year = NULL,
        i.to.year = NULL,
        i.omit.years = NULL,
        i.denominator.dimensions = NULL,
        i.equalize.weight.by.year = NULL,
        i.parameters = NULL,
        i.sources.to.use = NULL,
        i.dimension.values = NULL, # EXPERIMENTAL
        i.use.lognormal.approximation = NULL,
        i.calculate.lagged.difference = NULL,
        i.is.basic.ratio.likelihood = NULL
    )
)

# class generator object
JHEEM.BASIC.LIKELIHOOD <- R6::R6Class(
    "jheem.basic.likelihood",
    inherit = JHEEM.LIKELIHOOD,
    portable = F,
    public = list(
        initialize = function(instructions,
                              version,
                              location, # combinations of version and location tell us sublocations
                              sub.version,
                              data.manager,
                              throw.error.if.no.data,
                              error.prefix) {
            super$initialize(
                instructions = instructions,
                sub.version = sub.version,
                version = version,
                location = location,
                error.prefix = error.prefix
            )
            
            # Validate *data.manager*, a 'jheem.data.manager' object
            if (!R6::is.R6(data.manager) || !is(data.manager, "jheem.data.manager")) {
                stop(paste0(error.prefix, "'data.manager' must be an R6 object with class 'jheem.data.manager'"))
            }
            
            private$i.version <- version
            private$i.sub.version <- sub.version
            private$i.location <- location
            
            private$i.parameters <- instructions$parameters
            private$i.outcome.for.data <- instructions$outcome.for.data
            private$i.outcome.value <- instructions$outcome.value
            
            private$i.dimension.values <- instructions$dimension.values # EXPERIMENTAL
            private$i.use.lognormal.approximation <- instructions$use.lognormal.approximation
            private$i.calculate.lagged.difference <- instructions$calculate.lagged.difference
            private$i.is.basic.ratio.likelihood <- instructions$is.basic.ratio.likelihood
            
            ## ---- DETERMINE YEARS FOR SIM METADATA ---- ##
            years <- get.likelihood.years(
                from.year = instructions$from.year,
                to.year = instructions$to.year,
                omit.years = instructions$omit.years,
                data.manager = data.manager,
                outcome.for.data = private$i.outcome.for.data
            )
            
            ## ---- PREPARE DATA STRUCTURES ---- ##
            
            sim.metadata <- get.simulation.metadata(
                version = version, ## MOVE THIS TO MAIN LIKELIHOOD SINCE ALL WILL HAVE SIM METADATA?
                location = location,
                from.year = years[[1]],
                to.year = years[[length(years)]]
            )
            
            scale <- sim.metadata$outcome.metadata[[private$i.outcome.for.sim]]$scale
            if (!(scale %in% c("non.negative.number", "number", "proportion", "rate"))) {
                stop(paste0(error.prefix, "'outcome.for.sim' must be a non.negative.number, number, rate, or proportion"))
            }
            private$i.outcome.is.proportion <- scale == "proportion"
            private$i.outcome.is.rate <- scale == "rate"
            private$i.outcome.is.count <- !private$i.outcome.is.proportion && !private$i.outcome.is.rate
            
            # if (private$i.outcome.is.proportion && is.null(private$i.denominator.outcome.for.sim)) {
            #     private$i.denominator.outcome.for.sim = sim.metadata$outcome.metadata[[private$i.outcome.for.sim]]$denominator.outcome
            #     #        if (is.null(private$i.denominator.outcome.for.sim))
            #     #            stop(paste0(error.prefix, "denominator data expected for this outcome but not found"))
            # }
            
            private$i.sim.ontology <- sim.metadata$outcome.ontologies[[private$i.outcome.for.sim]]
            private$i.sim.ontology$year <- as.character(years)
            private$i.sim.ontology <- do.call(ontology, c(private$i.sim.ontology, list(incomplete.dimensions = c("year", "location"))))
            
            # Validate that instructions asked for dimensions that are in sim ontology for this outcome, and no more.
            requested.dimensions <- setdiff(unique(unlist(private$i.stratifications)), "")
            dimensions.in.instr.not.sim <- requested.dimensions[!sapply(requested.dimensions, function(d) {
                d %in% names(private$i.sim.ontology)
            })]
            if (length(dimensions.in.instr.not.sim) > 0) {
                stop(paste0(error.prefix, "likelihood instructions requested the following dimensions not present in the simulation ontology for this outcome: ", paste(dimensions.in.instr.not.sim, collapse = ", ")))
            }
            
            
            private$i.obs.vector <- c()
            private$i.details <- c() # will contain each observation's sorted details as a collapsed character factor
            private$i.metadata <- data.frame(
                year = character(0),
                stratum = character(0),
                source = character(0)
            )
            
            dimnames.list <- list()
            remove.mask.list <- list()
            dv.remove.mask.list <- list() # EXPERIMENTAL
            private$i.transformation.matrix <- NULL
            private$i.sim.required.dimnames <- private$i.denominator.required.dimnames <- private$i.sim.dimension.values <- private$i.denominator.dimension.values <- list()
            
            ### EXPERIMENTAL: LIMIT STRATIFICATIONS TO ONLY THOSE WITH *ALL* THE DIMENSIONS FROM DIMENSION VALUES
            if (length(private$i.dimension.values) > 0) {
                private$i.stratifications <- private$i.stratifications[sapply(private$i.stratifications, function(stratification) {
                    setequal(stratification, names(private$i.dimension.values))
                })]
            }
            
            ## ---- PULL DATA ---- ##
            if (!is.null(private$i.outcome.value)) {
                private$i.obs.vector <- rep(private$i.outcome.value, length(years)) # need input.data
                private$i.details <- rep("supplied", length(years))
                private$i.metadata <- data.frame(year = years, stratum = ".TOTAL.", dimensions = ".TOTAL.", source = "supplied") # need to get years
                dimnames.list <- list(list(year = as.character(years), source = "supplied"))
                remove.mask.list <- list(rep(F, length(years)))
                dv.remove.mask.list <- remove.mask.list
                one.mapping <- get.identity.ontology.mapping()
                private$i.sim.required.dimnames <- one.mapping$get.required.from.dim.names(dimnames.list[[1]])
                n.stratifications.with.data <- 1
                private$i.metadata$source <- as.factor(private$i.metadata$source)
            } else {
                n.stratifications.with.data <- 0
                # browser()
                for (strat in private$i.stratifications) {
                    # print(paste(strat, collapse ="__"))
                    keep.dimensions <- "year"
                    if (!identical(strat, "")) keep.dimensions <- c(keep.dimensions, strat)
                    # if (identical(strat, c('age', 'race'))) browser()
                    data <- data.manager$pull(
                        outcome = private$i.outcome.for.data,
                        sources = instructions$sources.to.use,
                        keep.dimensions = keep.dimensions,
                        dimension.values = list(year = as.character(years), location = location), # leave this for now. Will get more complicated when we have multi location models
                        target.ontology = private$i.sim.ontology,
                        allow.mapping.from.target.ontology = T,
                        append.attributes = "details",
                        debug = F)
                    
                    if (is.null(data)) {
                        if (throw.error.if.no.data) {
                            stop(paste0(error.prefix, "no data was found for the stratification '", strat, "'"))
                        } else {
                            next
                        }
                    }
                    
                    n.stratifications.with.data <- n.stratifications.with.data + 1
                    one.mapping <- attr(data, "mapping")
                    one.dimnames <- dimnames(data)
                    one.details <- attr(data, "details")
                    
                    ## Pull measurement error variance if needed
                    if (instructions$parameters$error.variance.type %in% c("data.sd", "data.variance", "data.cv")) {
                        metric.map <- list(data.sd = "sd", data.variance = "variance", data.cv = "coefficient.of.variance")
                        error.data <- data.manager$pull(
                            outcome = private$i.outcome.for.data,
                            metric = metric.map[[private$i.parameters$error.variance.type]],
                            sources = private$i.sources.to.use,
                            keep.dimensions = keep.dimensions,
                            dimension.values = list(year = as.character(years), location = location),
                            target.ontology = private$i.sim.ontology,
                            allow.mapping.from.target.ontology = T
                        )
                        
                        if (is.null(error.data)) {
                            if (throw.error.if.no.data) {
                                stop(paste0(error.prefix, "no ", metric.map[[private$i.parameters$error.variance.type]], ", data was found for the stratification '", strat, "'"))
                            } else {
                                next
                            }
                        }
                        
                        # find overlapping dimnames, limit both, then flip data to NA if cv for that value is NA
                        common.dimnames <- get.dimension.values.overlap(dimnames(data), dimnames(error.data))
                        error.data <- array.access(error.data, common.dimnames)
                        data <- array.access(data, common.dimnames)
                        
                        if (instructions$parameters$error.variance.type == "data.cv") {
                            error.data <- data * error.data
                        } # sd = cv * mean ... Note that "data" has not been lognormal transformed yet, so we don't need to do exp(data)
                        
                        data[is.na(error.data)] <- NA
                        one.details <- array.access(one.details, common.dimnames)
                        
                        one.error.data <- as.numeric(error.data) # na masks will align perfectly with obs p mask
                        one.error.data <- one.error.data[!is.na(one.error.data)]
                        
                        if (instructions$parameters$error.variance.type == "data.variance") {
                            one.error.data <- sqrt(one.error.data)
                        }
                        
                        private$i.error.vector <- c(private$i.error.vector, one.error.data)
                    }
                    
                    # If using a function to generate variance data, follow similar pattern to above
                    if (instructions$parameters$error.variance.type %in% c("function.sd")) {
                        error.data <- tryCatch({instructions$parameters$error.variance.term(data, one.details)},
                                               error=function(e) {stop(paste0(error.prefix, "there was an error during execution of the user-specified 'error.variance.term' function"))})
                        if (is.null(error.data))
                            stop(paste0(error.prefix, "user-specified 'error.variance.term' function returned NULL"))
                        if (!is.array(error.data) || !is.numeric(error.data) || !identical(dimnames(error.data), dimnames(data)))
                            stop(paste0(error.prefix, "user-specified 'error.variance.term' function did not return a numeric array with the same dimnames as the data"))
                        if (any(is.na(error.data)))
                            stop(paste0(error.prefix, "user-specified 'error.variance.term' function returned at least one NA and must not"))
                        private$i.error.vector <- c(private$i.error.vector, error.data)
                    }
                    
                    # If we have lognormal approximation on, we should remove observations that are 0.
                    if (private$i.use.lognormal.approximation) {
                        data[data == 0] <- NA
                    }
                    
                    # By this point, "data" may have had multiple entries converted to NA.
                    one.obs.vector <- as.numeric(data)
                    
                    # EXPERIMENTAL
                    one.dimension.values.remove.mask <- rep(T, length(one.obs.vector)) # EXPERIMENTAL
                    one.dimension.values.remove.mask[get.array.access.indices(one.dimnames, dimension.values = private$i.dimension.values)] <- F # EXPERIMENTAL
                    dv.remove.mask.list <- c(dv.remove.mask.list, list(one.dimension.values.remove.mask)) # EXPERIMENTAL
                    
                    one.remove.mask <- is.na(one.obs.vector)
                    one.obs.vector <- one.obs.vector[!one.remove.mask]
                    one.details <- one.details[!one.remove.mask]
                    
                    # Metadata will involve melting both arrays (data and details) as well as making "stratum"
                    one.metadata <- reshape2::melt(data)
                    one.metadata <- one.metadata[!one.remove.mask, ]
                    
                    # Recover required dimnames from one.metadata
                    one.sim.required.dimnames <- one.mapping$get.required.from.dim.names(lapply(
                        one.metadata[!(colnames(one.metadata) %in% c("source", "value"))],
                        function(x) {
                            as.character(unique(x))
                        }
                    ))
                    
                    one.metadata <- one.metadata[, sort(colnames(one.metadata))]
                    one.metadata["stratum"] <- do.call(paste, c(subset.data.frame(one.metadata, select = -c(year, source, value)), sep = "__"))
                    one.metadata[is.na(one.metadata$stratum), "stratum"] <- ".TOTAL."
                    one.metadata["dimensions"] <- paste0(strat, collapse = "__")
                    one.metadata <- subset.data.frame(one.metadata, select = c(year, stratum, dimensions, source))
                    
                    # Find the required.dimnames
                    for (d in names(one.sim.required.dimnames)) {
                        if (!(d %in% names(private$i.sim.required.dimnames))) {
                            private$i.sim.required.dimnames <- c(private$i.sim.required.dimnames, setNames(list(one.sim.required.dimnames[[d]]), d))
                        } else {
                            private$i.sim.required.dimnames[[d]] <- union(private$i.sim.required.dimnames[[d]], one.sim.required.dimnames[[d]])
                        }
                    }
                    
                    # Convert one.details list of vectors to a list of characters of collapsed sorted details, then unlist to a vector
                    one.details <- unlist(lapply(one.details, function(v) {
                        paste(sort(v), collapse = "__")
                    }))
                    
                    private$i.obs.vector <- c(private$i.obs.vector, one.obs.vector)
                    private$i.details <- c(private$i.details, one.details)
                    private$i.metadata <- rbind(private$i.metadata, one.metadata)
                    dimnames.list <- c(dimnames.list, list(one.dimnames))
                    remove.mask.list <- c(remove.mask.list, list(one.remove.mask))
                }
            }
            
            private$i.n.obs <- length(private$i.obs.vector)
            
            if (n.stratifications.with.data == 0) {
                stop(paste0(error.prefix, "No data found for any stratifications"))
            }
            # browser()
            # NOTE: STRATUM MUST BE RESTORED TO CHARACTER LATER WHEN WE GENERATE THE WEIGHTS MATRIX SINCE WE HAVE TO STRING SPLIT IT
            private$i.details <- as.factor(private$i.details)
            # private$i.metadata$location = as.factor(private$i.metadata$location) # already factor somehow
            if (private$i.parameters$observation.correlation.form == "autoregressive.1") {
                private$i.metadata$year <- suppressWarnings(as.numeric(private$i.metadata$year))
                if (any(is.na(private$i.metadata$year))) {
                    stop(paste0(error.prefix, "'observation.correlation.form' 'autoreggresive.1' can only be used with single-year data points"))
                }
            } else {
                private$i.metadata$year <- as.factor(private$i.metadata$year)
            }
            private$i.metadata$stratum <- as.factor(private$i.metadata$stratum)
            # private$i.metadata$source = as.factor(private$i.metadata$source) # already factor somehow
            
            ## ---- FIND REQUIRED DIMENSION VALUES, ETC. ---- ##
            if (private$i.is.basic.ratio.likelihood) {
                corrected.sim.required.dimnames <- private$i.sim.ontology[names(private$i.sim.ontology) != "location"]
                corrected.sim.required.dimnames$year <- sort(private$i.sim.required.dimnames$year)
                private$i.sim.required.dimnames <- private$i.denominator.required.dimnames <- corrected.sim.required.dimnames
                
                private$i.years <- private$i.sim.required.dimnames[["year"]]
                private$i.sim.dimension.values <- private$i.denominator.dimension.values <- private$i.sim.required.dimnames["year"]
            } else {
                corrected.sim.required.dimnames <- private$i.sim.ontology[names(private$i.sim.ontology) %in% names(private$i.sim.required.dimnames)]
                corrected.sim.required.dimnames$year <- sort(private$i.sim.required.dimnames$year)
                private$i.sim.required.dimnames <- corrected.sim.required.dimnames
                
                private$i.years <- private$i.sim.required.dimnames[["year"]]
                private$i.sim.dimension.values <- private$i.sim.required.dimnames[sapply(names(private$i.sim.required.dimnames), function(d) {
                    !identical(private$i.sim.required.dimnames[[d]], private$i.sim.ontology[[d]])
                })]
                private$i.sim.dimension.values[["year"]] <- private$i.years
                
                denominator.keep.dimensions <- c(instructions$denominator.dimensions, "year")[c(instructions$denominator.dimensions, "year") %in% names(private$i.sim.required.dimnames)]
                private$i.denominator.required.dimnames <- private$i.sim.required.dimnames[names(private$i.sim.required.dimnames) %in% denominator.keep.dimensions]
                private$i.denominator.dimension.values <- private$i.denominator.required.dimnames[sapply(names(private$i.denominator.required.dimnames), function(d) {
                    !identical(private$i.denominator.required.dimnames[[d]], private$i.sim.ontology[[d]])
                })]
                private$i.denominator.dimension.values[["year"]] <- private$i.years
            }
            # browser()
            ## ---- GENERATE TRANSFORMATION MATRIX ---- ##
            private$i.transformation.matrix <- generate.transformation.matrix(dimnames.list, remove.mask.list, n.stratifications.with.data, private$i.sim.required.dimnames)
            
            if (is.null(private$i.transformation.matrix)) {
                stop(paste0(error.prefix, "no mappings found to align simulation and data ontologies"))
            }
            
            ## ---- EXPERIMENTAL: CREATE DIMENSION VALUES MASK ---- ##
            # APPLY IT TO TRANSFORMATION MATRIX, OBS VECTOR, METADATA
            dv.shortened.remove.mask <- unlist(dv.remove.mask.list)[!unlist(remove.mask.list)]
            private$i.transformation.matrix <- private$i.transformation.matrix[!dv.shortened.remove.mask, ]
            private$i.obs.vector <- private$i.obs.vector[!dv.shortened.remove.mask]
            private$i.metadata <- private$i.metadata[!dv.shortened.remove.mask, ]
            private$i.n.obs <- length(private$i.obs.vector)
            
            ## ---- GENERATE SPARSE REPRESENTATIONS OF TRANSFORMATION MATRIX ---- ##
            if (!private$i.is.basic.ratio.likelihood) {
                private$i.transformation.matrix.indices <- generate_transformation_matrix_indices(
                    private$i.transformation.matrix,
                    private$i.n.obs,
                    length(private$i.transformation.matrix) / private$i.n.obs
                )
                
                private$i.transformation.matrix.row.oriented.indices <- generate_transformation_matrix_row_oriented_indices(
                    private$i.transformation.matrix,
                    private$i.n.obs,
                    length(private$i.transformation.matrix) / private$i.n.obs
                )
            }
            
            ## ---- GENERATE MEASUREMENT ERROR COVARIANCE MATRIX ---- ##
            
            # call this function with numeric(0) replacing the locations vector and 1 replacing the correlation different locations, used in the nested proportion likelihood.
            measurement.error.correlation.matrix <- get_obs_error_correlation_matrix(
                rep(1, private$i.n.obs**2),
                private$i.n.obs,
                numeric(0),
                as.numeric(private$i.metadata$year),
                as.numeric(private$i.metadata$stratum),
                as.numeric(private$i.metadata$source),
                as.numeric(private$i.details),
                1,
                private$i.parameters$correlation.different.year,
                private$i.parameters$correlation.different.strata,
                private$i.parameters$correlation.different.source,
                private$i.parameters$correlation.same.source.different.details,
                private$i.parameters$observation.correlation.form == "autoregressive.1"
            )
            # if we get measurement error sd from data, we'll need to have pulled it along with the regular data
            
            # TO DO: error variance if it's by year
            
            # All forms of error will be converted to sd and then we use cov = corr * sd %*% t(sd), the last part sometimes being just sd squared
            if (private$i.parameters$error.variance.type %in% c("data.sd", "data.variance", "data.cv", "function.sd")) {
                # all have been converted to sd earlier, including data.cv
                measurement.error.sd.matrix <- private$i.error.vector %*% t(private$i.error.vector)
                private$i.measurement.error.covariance.matrix <- measurement.error.correlation.matrix * measurement.error.sd.matrix
            } else if (private$i.parameters$error.variance.type == "sd") {
                private$i.measurement.error.covariance.matrix <- measurement.error.correlation.matrix * private$i.parameters$error.variance.term^2
            } # this reflects our choice to make measurement error sd constant, not scaling with level of suppression (or other p)
            else if (private$i.parameters$error.variance.type == "variance") {
                private$i.measurement.error.covariance.matrix <- measurement.error.correlation.matrix * private$i.parameters$error.variance.term
            } else if (private$i.parameters$error.variance.type == "cv") {
                if (private$i.use.lognormal.approximation) {
                    measurement.error.sd <- exp(private$i.obs.vector) * private$i.parameters$error.variance.term
                } else {
                    measurement.error.sd <- private$i.obs.vector * private$i.parameters$error.variance.term
                }
                private$i.measurement.error.covariance.matrix <- measurement.error.correlation.matrix * (measurement.error.sd %*% t(measurement.error.sd))
            }
            
            ## included multiplier to make inverse multiplier matrix times covariance matrix
            if (!is.null(private$i.parameters$included.multiplier)) {
                if (!is.null(names(private$i.parameters$included.multiplier))) {
                    if (any(!(private$i.metadata$year %in% names(private$i.parameters$included.multiplier)))) {
                        stop(paste0(error.prefix, "all years values in data must have a corresponding 'included.multiplier'"))
                    }
                    
                    included.multiplier.vector <- sapply(private$i.metadata$year, function(obs.year) {
                        private$i.parameters$included.multiplier[obs.year]
                    })
                    included.multiplier.sd.vector <- sapply(private$i.metadata$year, function(obs.year) {
                        private$i.parameters$included.multiplier.sd[obs.year]
                    })
                } else {
                    included.multiplier.vector <- rep(private$i.parameters$included.multiplier, private$i.n.obs)
                    included.multiplier.sd.vector <- rep(private$i.parameters$included.multiplier.sd, private$i.n.obs)
                }
                
                inverse.multiplier.matrix <- (1 / included.multiplier.vector) %*% t(1 / included.multiplier.vector)
                
                # AR.1 cannot be selected if we have year ranges because year ranges do not have distance measures
                if (private$i.parameters$included.multiplier.correlation.form == "autoregressive.1" && any(is.year.range(private$i.metadata$year))) {
                    stop(paste0(error.prefix, "instructions cannot use 'autoregressive.1' for 'included.multiplier.correlation.form' since observations with year ranges were found"))
                }
                
                multiplier.correlation.matrix <- get_multiplier_correlation_matrix(
                    rep(1, private$i.n.obs**2),
                    private$i.n.obs,
                    as.numeric(private$i.metadata$year),
                    private$i.parameters$included.multiplier.correlation,
                    private$i.parameters$included.multiplier.correlation.structure == "autoregressive.1"
                )
                multiplier.covariance.matrix <- multiplier.correlation.matrix * included.multiplier.sd.vector %*% t(included.multiplier.sd.vector)
                private$i.inverse.multiplier.matrix.times.cov.mat <- inverse.multiplier.matrix * multiplier.covariance.matrix
            }
            
            ## ---- GENERATE INVERSE VARIANCE WEIGHTS MATRIX ---- ##
            private$i.metadata$stratum <- as.character(private$i.metadata$stratum)
            private$i.inverse.variance.weights.matrix <- generate.inverse.variance.weights.matrix(
                obs.vector = private$i.obs.vector,
                equalize.weight.by.year = instructions$equalize.weight.by.year,
                metadata = private$i.metadata,
                weights = private$i.weights
            )
            
            ## ---- SAVE THE PREPARED OPTIMIZED GET INSTRUCTIONS ---- ##
            # browser()
            private$i.optimized.get.instructions <- list()
            private$i.optimized.get.instructions[["sim.num.instr"]] <- sim.metadata$prepare.optimized.get.instructions(
                outcomes = private$i.outcome.for.sim,
                keep.dimensions = names(private$i.sim.required.dimnames),
                dimension.values = private$i.sim.dimension.values,
                output = "numerator",
                drop.single.sim.dimension = T
            )
            if (private$i.outcome.is.proportion || private$i.outcome.is.rate) {
                private$i.optimized.get.instructions[["sim.denom.instr"]] <- sim.metadata$prepare.optimized.get.instructions(
                    outcome = private$i.outcome.for.sim,
                    keep.dimensions = names(private$i.denominator.required.dimnames),
                    dimension.values = private$i.denominator.dimension.values,
                    output = "denominator",
                    drop.single.sim.dimension = T
                )
            }
            
            ## ---- GENERATE LAGGED PAIRS IF REQUESTED ---- ##
            if (private$i.calculate.lagged.difference) {
                year.for.lag <- suppressWarnings(as.numeric(private$i.metadata$year))
                if (any(is.na(year.for.lag))) {
                    stop(paste0(error.prefix, "'calculate.lagged.difference' can only be used with single-year data points"))
                }
                private$i.lagged.pairs <- generate_lag_matrix_indices(
                    year.for.lag, # check if valid -- no year ranges, please!
                    rep(0, nrow(private$i.metadata)), # location not used for basic likelihoods but is available for nested prop likelihoods
                    as.integer(as.factor(private$i.metadata$stratum)),
                    as.integer(as.factor(private$i.metadata$source)),
                    private$i.n.obs
                )
                if (length(private$i.lagged.pairs) == 0) {
                    stop(paste0(error.prefix, "no data found for lagged-year pairs"))
                }
                private$i.n.lagged.obs <- length(private$i.lagged.pairs) / 2
                
                if (!is.null(private$i.parameters$ratio.cv)) {
                    val = (log(private$i.parameters$ratio.cv) / qnorm(0.975))**2
                    private$i.log.ratio.uncertainty.matrix = matrix(
                        val * private$i.parameters$ratio.correlation,
                        nrow = private$i.n.lagged.obs,
                        ncol = private$i.n.lagged.obs)
                    diag(private$i.log.ratio.uncertainty.matrix) = val
                }
                
                # Keep only the latter years for each pair
                private$i.metadata.for.lag <- private$i.metadata[private$i.lagged.pairs[rep(c(T, F), private$i.n.lagged.obs)] + 1, ]
            }
        },
        get.outcome.location.mapping = function() {
            create.outcome.location.mapping(
                location.mappings = setNames(list(private$i.location), private$i.location),
                outcome.name = private$i.outcome.for.data,
                version = private$i.version,
                location = private$i.location,
                sub.version = private$i.sub.version
            )
        },
        check = function() {
            browser()
        }
    ),
    private = list(
        i.version = NULL,
        i.location = NULL,
        i.sub.version = NULL,
        i.parameters = NULL,
        i.outcome.for.data = NULL,
        i.outcome.is.proportion = NULL,
        i.outcome.is.rate = NULL,
        i.outcome.is.count = NULL,
        i.outcome.value = NULL,
        i.optimized.get.instructions = NULL,
        i.obs.vector = NULL,
        i.details = NULL,
        i.metadata = NULL,
        i.sim.ontology = NULL,
        i.sim.required.dimnames = NULL,
        i.denominator.required.dimnames = NULL,
        i.sim.dimension.values = NULL,
        i.denominator.dimension.values = NULL,
        i.transformation.matrix = NULL,
        i.transformation.matrix.indices = NULL,
        i.transformation.matrix.row.oriented.indices = NULL,
        i.measurement.error.covariance.matrix = NULL,
        i.inverse.variance.weights.matrix = NULL,
        i.inverse.multiplier.matrix.times.cov.mat = NULL,
        i.n.obs = NULL,
        i.n.lagged.obs = NULL,
        i.dimension.values = NULL, # EXPERIMENTAL
        i.use.lognormal.approximation = NULL,
        i.calculate.lagged.difference = NULL,
        i.is.basic.ratio.likelihood = NULL,
        i.lagged.pairs = NULL,
        i.metadata.for.lag = NULL,
        i.error.vector = NULL,
        i.log.ratio.uncertainty.matrix = NULL,
       
        do.compute = function(sim, log, use.optimized.get, check.consistency, debug) {
            
            if (use.optimized.get) {
                sim.numerator.data <- sim$optimized.get(private$i.optimized.get.instructions[["sim.num.instr"]])
            } else {
                sim.numerator.data <- sim$get(
                    outcomes = private$i.outcome.for.sim,
                    keep.dimensions = names(private$i.sim.required.dimnames),
                    dimension.values = private$i.sim.dimension.values,
                    output = "numerator",
                    drop.single.sim.dimension = T
                )
            }
            
            # we use Poisson if we are neither a proportion nor have a denominator outcome for sim provided
            # Rates are always Poisson because they are not bounded 0-1, and p(1-p) could go negative!
            
            # if denom for sim is NULL, figure out if it's a proportion or not
            # if so, use a sim get requesting to get only the denominator
            use.poisson <- private$i.outcome.is.rate || private$i.outcome.is.count
            if (private$i.outcome.is.count) {
                sim.denominator.data <- numeric(0)
                expanded.sim.denominator.data <- numeric(0) # so as not to throw errors in cpp sigma
            } else {
                if (use.optimized.get) {
                    sim.denominator.data <- sim$optimized.get(private$i.optimized.get.instructions[["sim.denom.instr"]])
                } else {
                    sim.denominator.data <- sim$get(
                        outcome = private$i.outcome.for.sim,
                        keep.dimensions = names(private$i.denominator.required.dimnames),
                        dimension.values = private$i.denominator.dimension.values,
                        output = "denominator",
                        drop.single.sim.dimension = T
                    )
                }
                expanded.sim.denominator.data <- expand.array(sim.denominator.data, dimnames(sim.numerator.data))
            }
            
            # Re-purpose likelihood mean code to find aggregated N matrix (diagonal, so treated as vector)
            n.vector <- NULL
            if (private$i.outcome.is.proportion || private$i.outcome.is.rate) {
                n.vector <- get_basic_likelihood_mean(
                    expanded.sim.denominator.data,
                    private$i.transformation.matrix.row.oriented.indices,
                    private$i.n.obs,
                    numeric(private$i.n.obs)
                )
            }
            
            # Warning! These don't throw an error when sim.numerator.data isn't long enough!
            mean <- get_basic_likelihood_mean(
                sim.numerator.data,
                private$i.transformation.matrix.row.oriented.indices,
                private$i.n.obs,
                numeric(private$i.n.obs)
            )
            
            if (private$i.outcome.is.proportion ||
                (private$i.outcome.is.rate && !(private$i.use.lognormal.approximation && private$i.calculate.lagged.difference))) {
                obs <- private$i.obs.vector * n.vector
                measurement.error.cov.mat <- n.vector %*% t(n.vector) * private$i.measurement.error.covariance.matrix
            } else {
                obs <- private$i.obs.vector
                measurement.error.cov.mat <- private$i.measurement.error.covariance.matrix
            }
            
            sigma <- get_basic_likelihood_sigma(sim.numerator.data,
                                                expanded.sim.denominator.data,
                                                private$i.transformation.matrix.indices,
                                                measurement.error.cov.mat,
                                                private$i.n.obs,
                                                sigma = numeric(private$i.n.obs^2), # maybe define before this?
                                                use.poisson
            )
            
            # Revise sigma if including multiplier
            if (!is.null(private$i.inverse.multiplier.matrix.times.cov.mat)) {
                sigma.minus.measurement.error <- sigma - measurement.error.cov.mat
                sigma <- sigma + private$i.inverse.multiplier.matrix.times.cov.mat * (sigma.minus.measurement.error + mean %*% t(mean))
            }
            
            sigma <- sigma * private$i.inverse.variance.weights.matrix
            
            
            if (private$i.use.lognormal.approximation) {
                mean.reciprocal <- 1 / mean
                sigma <- log(mean.reciprocal %*% t(mean.reciprocal) * sigma + 1)
                mean <- log(mean) - diag(sigma) / 2
                obs <- log(obs)
            }
            
            if (private$i.calculate.lagged.difference) {
                obs <- apply_lag_to_vector(
                    obs,
                    private$i.lagged.pairs,
                    rep(0, private$i.n.lagged.obs),
                    private$i.n.obs
                )
                mean <- apply_lag_to_vector(
                    mean,
                    private$i.lagged.pairs,
                    rep(0, private$i.n.lagged.obs),
                    private$i.n.obs
                )
                sigma <- apply_lag_to_matrix(
                    sigma,
                    private$i.lagged.pairs,
                    rep(0, private$i.n.lagged.obs**2),
                    private$i.n.obs
                )
                dim(sigma) <- c(private$i.n.lagged.obs, private$i.n.lagged.obs)
                # mean = private$i.lag.matrix %*% mean
                # sigma = private$i.lag.matrix %*% sigma %*% private$i.transposed.lag.matrix # there is a more efficient way to do this if we know there are only two non-zero elements per row in lag matrix
                
                # to do at instantiate time: obs = private$i.lag.matrix %*% obs
            }
            
            if (!is.null(private$i.log.ratio.uncertainty.matrix))
                sigma = sigma + private$i.log.ratio.uncertainty.matrix
            
            likelihood <- mvtnorm::dmvnorm(obs,
                                           mean = mean,
                                           sigma = sigma,
                                           log = T,
                                           checkSymmetry = F
            )
            
            if (debug) {
                if (private$i.calculate.lagged.difference) {
                    lik.summary <- cbind(private$i.metadata.for.lag, obs = obs, mean = mean, sd = sqrt(diag(sigma)))
                } else if (!is.null(n.vector)) {
                    lik.summary <- cbind(private$i.metadata, obs = obs / n.vector, mean = mean / n.vector, sd = sqrt(diag(sigma)) / n.vector)
                } else {
                    lik.summary <- cbind(private$i.metadata, obs = obs, mean = mean, sd = sqrt(diag(sigma)))
                }
                
                lik.summary$z <- (lik.summary$obs - lik.summary$mean) / lik.summary$sd
                rownames(lik.summary) <- 1:nrow(lik.summary)
                browser()
            }
            return(likelihood)
            
            # verify.matrix.operation.correctness(sim.denominator.data,
            #                                     sim.numerator.data,
            #                                     private$i.transformation.matrix,
            #                                     private$i.measurement.error.covariance.matrix,
            #                                     private$i.inverse.variance.weights.matrix,
            #                                     private$i.obs.vector,
            #                                     likelihood,
            #                                     log)
        },
        generate.transformation.matrix = function(dimnames.list, remove.mask.list, n.strats, sim.dimnames, debug = F) {
            if (debug) browser()
            transformation.matrix <- NULL
            for (i in 1:n.strats) {
                one.dimnames <- dimnames.list[[i]]
                one.remove.mask <- remove.mask.list[[i]]
                
                # "row year" means years as described by the data, which may year single years or ranges
                # "column year" means years as described by the model, which is always single years
                
                row.years.in.both.data.and.sim <- get.range.robust.year.intersect(one.dimnames$year, sim.dimnames$year)
                col.years.in.both.data.and.sim <- get.range.robust.year.intersect(sim.dimnames$year, one.dimnames$year)
                row.years.in.data.but.not.sim <- setdiff(one.dimnames$year, row.years.in.both.data.and.sim)
                col.years.in.sim.but.not.data <- setdiff(sim.dimnames$year, col.years.in.both.data.and.sim)
                
                # we must add rows that we'll soon delete so that every column year has a row year/range to map to
                row.years.for.initial.tmat <- c(row.years.in.both.data.and.sim, col.years.in.sim.but.not.data)
                
                year.modified.dimnames <- one.dimnames
                year.modified.dimnames$year <- row.years.for.initial.tmat
                year.modified.dimnames.without.source <- year.modified.dimnames[names(year.modified.dimnames) != "source"]
                
                one.mapping <- get.ontology.mapping(from.ontology = sim.dimnames, to.ontology = year.modified.dimnames.without.source)
                one.source.transformation.matrix <- one.mapping$get.matrix(
                    from.dim.names = sim.dimnames,
                    to.dim.names = year.modified.dimnames.without.source
                )
                
                # Remove rows for years not in this stratification
                if (length(col.years.in.sim.but.not.data) > 0) {
                    indices.for.years.not.present <- get.array.access.indices(year.modified.dimnames.without.source, list(year = col.years.in.sim.but.not.data))
                    one.source.transformation.matrix <- one.source.transformation.matrix[-indices.for.years.not.present, ]
                }
                
                # Repeat the matrix for each source this stratification has
                one.transformation.matrix <- NULL
                for (source in 1:length(one.dimnames$source)) one.transformation.matrix <- rbind(one.transformation.matrix, one.source.transformation.matrix)
                ncol.in.matrix <- ncol(one.transformation.matrix)
                
                # Align the matrix rows with the one.remove.mask rows, which may have extra years, so that rows for sporadically missing data can be masked out
                if (length(row.years.in.data.but.not.sim) > 0) {
                    indices.to.omit.from.one.remove.mask <- get.array.access.indices(one.dimnames, list(year = row.years.in.data.but.not.sim))
                    new.one.remove.mask <- one.remove.mask[-indices.to.omit.from.one.remove.mask]
                    one.transformation.matrix <- one.transformation.matrix[!new.one.remove.mask, ]
                } else {
                    one.transformation.matrix <- one.transformation.matrix[!one.remove.mask]
                }
                one.transformation.matrix <- matrix(one.transformation.matrix, ncol = ncol.in.matrix)
                transformation.matrix <- rbind(transformation.matrix, one.transformation.matrix)
            }
            transformation.matrix
        },
        generate.inverse.variance.weights.matrix = function(obs.vector,
                                                            equalize.weight.by.year,
                                                            metadata,
                                                            weights) {
            weights.vector <- rep(1, length(obs.vector))
            
            if (equalize.weight.by.year) {
                obs.per.year <- table(metadata$year)
                number.years <- length(obs.per.year)
                
                for (year in names(obs.per.year)) {
                    weights.vector[metadata$year == year] <- length(obs.vector) / (obs.per.year[[year]] * number.years)
                }
            }
            
            data.dimension.values <- apply(metadata, MARGIN = 1, function(row) {
                stratum <- unlist(strsplit(row[["stratum"]], "__"))
                dimensions <- unlist(strsplit(row[["dimensions"]], "__"))
                rv <- setNames(c(list(row[["year"]]), as.list(stratum)), c("year", dimensions))
            })
            
            # Once the weights list is in the format list(weights.object1, weights.object2, ...), I'll loop over them.
            for (weight in weights) {
                # if no dimension.values, apply it to all observations
                if (length(weight$dimension.values) == 0) {
                    weights.vector <- weights.vector * weight$total.weight
                } else {
                    weights.mask <- sapply(data.dimension.values, function(row) {
                        dimensions.this.weight <- names(weight$dimension.values)
                        if (!all(dimensions.this.weight %in% names(row))) {
                            return(F)
                        }
                        all(sapply(dimensions.this.weight, function(dimension) {
                            row[[dimension]] %in% weight$dimension.values[[dimension]] # weight can have multiple values per dimension
                        }))
                    })
                    weights.vector[weights.mask] <- weights.vector[weights.mask] * weight$total.weight
                }
            }
            
            sqrt.weights.vector <- sqrt(1 / weights.vector)
            sqrt.weights.vector %*% t(sqrt.weights.vector)
        },
        verify.matrix.operation.correctness = function(sim.denominator.data,
                                                       sim.numerator.data,
                                                       transformation.matrix,
                                                       measurement.error.covariance.matrix,
                                                       inverse.variance.weights.matrix,
                                                       obs.vector,
                                                       value.to.compare,
                                                       log) {
            sim.denominator.data <- as.vector(sim.denominator.data)
            sim.numerator.data <- as.vector(sim.numerator.data)
            
            transformed.numerator.data <- transformation.matrix %*% sim.numerator.data
            
            model.imperfection.error.variance <-
                sim.numerator.data * (1 - sim.numerator.data / sim.denominator.data)
            model.imperfection.error.covariance.matrix <- diag(model.imperfection.error.variance, nrow = length(model.imperfection.error.variance), ncol = length(model.imperfection.error.variance))
            
            transformed.model.imperfection.error.covariance.matrix <-
                transformation.matrix %*%
                model.imperfection.error.covariance.matrix %*%
                t(transformation.matrix)
            
            # sigma
            overall.covariance.matrix <- measurement.error.covariance.matrix + transformed.model.imperfection.error.covariance.matrix
            overall.covariance.matrix <- overall.covariance.matrix * inverse.variance.weights.matrix
            computed.value <- mvtnorm::dmvnorm(obs.vector,
                                               mean = transformed.numerator.data,
                                               sigma = overall.covariance.matrix,
                                               log = log,
                                               checkSymmetry = F
            )
            if (computed.value == value.to.compare) {
                print("Outputs match")
            } else {
                print("Outputs do not match")
            }
        }
    )
)
